{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'import_capacity', 'upward_dispatch_published',\n",
       "       'downward_dispatch_published', 'min_price_published',\n",
       "       'mid_price_published', 'max_price_published', 'minute_in_ptu',\n",
       "       'min_ptu_price_known', 'max_ptu_price_known',\n",
       "       'igcc_contribution_down_published', 'igcc_contribution_up_published',\n",
       "       'settlement_price_bestguess', 'time_since_last_two_sided',\n",
       "       'two_sided_daily_count', 'vwap_avg', 'vwap_std', 'vwap_median',\n",
       "       'vwap_qty_sum', 'vwap_max', 'hvq_delta', 'PTU', 'target_two_sided_ptu',\n",
       "       'settlement_price_realized', 'naive_strategy_action', 'forecast_wind',\n",
       "       'forecast_solar', 'forecast_demand', 'ptu_id',\n",
       "       'target_two_sided_ptu_alt', 'target_two_sided_ptu_realtime',\n",
       "       'target_two_sided_ptu_flip', 'fix_two_sided_ptu',\n",
       "       'fix_two_sided_ptu_alt', 'fix_two_sided_ptu_realtime',\n",
       "       'fix_two_sided_ptu_flip', 'is_balanced', 'residual_load',\n",
       "       'dispatch_diff', 'igcc_diff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tweedejaars_project import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.neural_network import *\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer, MissingIndicator\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.tree._criterion import ClassificationCriterion\n",
    "from sklearn.tree._splitter import BestSplitter\n",
    "import math\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "df = load_df()\n",
    "\n",
    "def add_is_balanced(df):\n",
    "    df[\"is_balanced\"] = df[\"min_price_published\"].isna() & df[\"max_price_published\"].isna()\n",
    "    return df\n",
    "\n",
    "df = add_is_balanced(df)\n",
    "\n",
    "df[\"residual_load\"] = df[\"forecast_demand\"] - df[\"forecast_solar\"] - df[\"forecast_wind\"]\n",
    "df[\"dispatch_diff\"] = df[\"upward_dispatch_published\"] - df[\"downward_dispatch_published\"]\n",
    "df[\"igcc_diff\"] = df[\"igcc_contribution_up_published\"] - df[\"igcc_contribution_down_published\"]\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"import_capacity\",\n",
    "    \"min_price_published\",\n",
    "    \"mid_price_published\",\n",
    "    \"max_price_published\",\n",
    "    \"min_ptu_price_known\",\n",
    "    \"max_ptu_price_known\",\n",
    "    \"upward_dispatch_published\",\n",
    "    \"downward_dispatch_published\",\n",
    "    \"time_since_last_two_sided\",\n",
    "    \"two_sided_daily_count\",\n",
    "    \"PTU\",\n",
    "    \"naive_strategy_action\",\n",
    "    \"vwap_avg\",\n",
    "    \"vwap_std\",\n",
    "    \"vwap_median\",\n",
    "    \"vwap_qty_sum\",\n",
    "    \"hvq_delta\",\n",
    "    \"forecast_wind\",\n",
    "    \"forecast_solar\",\n",
    "    \"forecast_demand\",\n",
    "    \"target_two_sided_ptu_realtime\",\n",
    "    \"residual_load\",\n",
    "    \"dispatch_diff\",\n",
    "    \"igcc_diff\",\n",
    "    \"is_balanced\"\n",
    "]\n",
    "\n",
    "features = ['naive_strategy_action', 'min_ptu_price_known',\n",
    "            'min_price_published', 'forecast_wind',\n",
    "            'time_since_last_two_sided',\n",
    "            'two_sided_daily_count', 'mid_price_published',\n",
    "            'vwap_avg', 'vwap_std', 'vwap_qty_sum',\n",
    "            'minute_in_ptu', 'downward_dispatch_published',\n",
    "            'settlement_price_bestguess', 'import_capacity',\n",
    "            'upward_dispatch_published',\n",
    "            'settlement_price_realized', 'forecast_solar',\n",
    "            'igcc_contribution_down_published', 'vwap_max',\n",
    "# 'min_price_diff',\n",
    "# 'residual_load',\n",
    "# 'balance',\n",
    "# 'import_zero',\n",
    "# 'dispatch_diff',\n",
    "# 'downward_dispatch_diff',\n",
    "# 'import_capacity_left',\n",
    "# 'igcc_down_diff',\n",
    "# 'forecast_wind_delta'\n",
    "]\n",
    "\n",
    "target = \"fix_two_sided_ptu\"\n",
    "version = \"target\"\n",
    "train_set = \"train\"\n",
    "test_set = \"valid\"\n",
    "\n",
    "splits = get_splits(df, features, target, return_dict_pair=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(labels, base=None):\n",
    "  \"\"\" Computes entropy of label distribution. \"\"\"\n",
    "\n",
    "  n_labels = len(labels)\n",
    "\n",
    "  if n_labels <= 1:\n",
    "    return 0\n",
    "\n",
    "  value,counts = np.unique(labels, return_counts=True)\n",
    "  probs = counts / n_labels\n",
    "  n_classes = np.count_nonzero(probs)\n",
    "\n",
    "  if n_classes <= 1:\n",
    "    return 0\n",
    "\n",
    "  ent = 0.\n",
    "\n",
    "  base = math.e if base is None else base\n",
    "  for i in probs:\n",
    "    ent -= i * math.log(i, base)\n",
    "\n",
    "  return ent\n",
    "\n",
    "def best_split_entropy(df, feature, target):\n",
    "    \"\"\"Calculate the information gain for a split on a numerical feature.\"\"\"\n",
    "    original_entropy = entropy(df[target])\n",
    "    best_gain = 0\n",
    "    best_split = None\n",
    "\n",
    "    sorted_values = np.sort(df[feature].unique())\n",
    "    for value in sorted_values:\n",
    "        left_split = df[df[feature] <= value][target]\n",
    "        right_split = df[df[feature] > value][target]\n",
    "\n",
    "        if len(left_split) == 0 or len(right_split) == 0:\n",
    "            continue\n",
    "\n",
    "        left_weight = len(left_split) / len(df)\n",
    "        right_weight = len(right_split) / len(df)\n",
    "        split_entropy = left_weight * entropy(left_split) + right_weight * entropy(right_split)\n",
    "\n",
    "        gain = original_entropy - split_entropy\n",
    "    \n",
    "        if gain > best_gain:\n",
    "            best_gain = gain\n",
    "            best_split = value\n",
    "\n",
    "    return best_gain, best_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hellinger_distance(N_A_parent, N_B_parent, N_A_left, N_B_left, N_A_right, N_B_right):\n",
    "\n",
    "    term_left = (np.sqrt(N_A_left / N_A_parent) - np.sqrt(N_B_left / N_B_parent)) ** 2\n",
    "    term_right = (np.sqrt(N_A_right / N_A_parent) - np.sqrt(N_B_right / N_B_parent)) ** 2\n",
    "\n",
    "    return term_left + term_right\n",
    "    \n",
    "\n",
    "def best_split_hellinger(df, feature, target):\n",
    "    \"\"\"Find the best split for a numerical feature using the Hellinger distance.\"\"\"\n",
    "    best_distance = float('inf')\n",
    "    best_split = None\n",
    "\n",
    "    sorted_values = np.sort(df[feature].unique())\n",
    "    N_A_parent = df[target].sum()\n",
    "    N_B_parent = len(df) - N_A_parent\n",
    "\n",
    "    for value in sorted_values:\n",
    "        left_split = df[df[feature] <= value]\n",
    "        right_split = df[df[feature] > value]\n",
    "\n",
    "        if len(left_split) == 0 or len(right_split) == 0:\n",
    "            continue\n",
    "\n",
    "        N_A_left = left_split[target].sum()\n",
    "        N_B_left = len(left_split) - N_A_left\n",
    "        N_A_right = right_split[target].sum()\n",
    "        N_B_right = len(right_split) - N_A_right\n",
    "\n",
    "        distance = hellinger_distance(N_A_parent, N_B_parent, N_A_left, N_B_left, N_A_right, N_B_right)\n",
    "\n",
    "        if distance < best_distance:\n",
    "            best_distance = distance\n",
    "            split_value = value\n",
    "\n",
    "    return best_distance, split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Node = namedtuple('Node', ['column_name',  'mode', 'branches'])\n",
    "\n",
    "def create_split(df, column, mode):\n",
    "    if df[column].unique() == 2:\n",
    "        split = {'left': df[df[column] == mode], 'right': df[df[column] != mode]}\n",
    "    else:\n",
    "        split = {'left': df[df[column] <= mode], 'right': df[df[column] > mode]}\n",
    "\n",
    "    return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ID3(data, target, max_depth=5):\n",
    "\n",
    "    # step 1\n",
    "    if data[target].nunique() == 1 or max_depth <= 0:\n",
    "      print(data[target])\n",
    "      return data[target].iloc[0]\n",
    "    print(f\"Layers to go = {max_depth}\")\n",
    "    max_depth -= 1\n",
    "\n",
    "    # step 2\n",
    "    # check if there's just the target left\n",
    "    if data.columns[0] == target and len(data.columns) == 1:\n",
    "      return data[target].mode()\n",
    "\n",
    "    # step 3\n",
    "    print(f\"step 3\")\n",
    "    distances = []\n",
    "    split_values = []\n",
    "    column_list = data.columns.drop(target)\n",
    "    for column in column_list:\n",
    "      print(column)\n",
    "      best_distance, split_value = best_split_hellinger(data, column, target)\n",
    "      distances.append(best_distance)\n",
    "      split_values.append(split_value)\n",
    "\n",
    "    # step 4\n",
    "    print(f\"step 4\")\n",
    "    max_idx = np.argmax(distances)\n",
    "    mode = split_values[max_idx]\n",
    "\n",
    "    # step 5\n",
    "    branches = {}\n",
    "    tree = Node(column_list[max_idx], mode, branches)\n",
    "\n",
    "    # step 6\n",
    "    print(f\"step 6\")\n",
    "    the_split = create_split(data, column_list[max_idx], split_values[max_idx])\n",
    "    for key in the_split.keys():\n",
    "      df = the_split[key]\n",
    "      new_branch = ID3(df, target, max_depth)\n",
    "      branches.update({key: new_branch})\n",
    "\n",
    "    # step 7\n",
    "    return tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers to go = 5\n",
      "step 2\n",
      "step 3\n",
      "f1\n",
      "f2\n",
      "f3\n",
      "step 4\n",
      "step 5\n",
      "step 6\n",
      "Node(column_name='f2', mode=0, branches={'left': 0, 'right': 1})\n"
     ]
    }
   ],
   "source": [
    "test_target = 'target'\n",
    "\n",
    "test_df = pd.DataFrame([[1, 1, 1, 1],\n",
    "                        [0, 0, 0, 0],\n",
    "                        [0, 1, 1, 1]],\n",
    "                        columns=['f1', 'f2', 'f3', 'target'])\n",
    "\n",
    "X_test = [[0, 0, 1]]\n",
    "y_test = [0]\n",
    "\n",
    "tree = ID3(test_df, test_target)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers to go = 2\n",
      "step 3\n",
      "naive_strategy_action\n",
      "min_ptu_price_known\n",
      "min_price_published\n",
      "forecast_wind\n",
      "time_since_last_two_sided\n",
      "two_sided_daily_count\n",
      "mid_price_published\n",
      "vwap_avg\n",
      "vwap_std\n",
      "vwap_qty_sum\n",
      "minute_in_ptu\n",
      "downward_dispatch_published\n",
      "settlement_price_bestguess\n",
      "import_capacity\n",
      "upward_dispatch_published\n",
      "settlement_price_realized\n",
      "forecast_solar\n",
      "igcc_contribution_down_published\n",
      "vwap_max\n",
      "step 4\n",
      "step 6\n",
      "dict_keys(['left', 'right'])\n",
      "Layers to go = 1\n",
      "step 3\n",
      "naive_strategy_action\n",
      "min_ptu_price_known\n",
      "min_price_published\n",
      "forecast_wind\n",
      "time_since_last_two_sided\n",
      "two_sided_daily_count\n",
      "mid_price_published\n",
      "vwap_avg\n",
      "vwap_std\n",
      "vwap_qty_sum\n",
      "minute_in_ptu\n",
      "downward_dispatch_published\n",
      "settlement_price_bestguess\n",
      "import_capacity\n",
      "upward_dispatch_published\n",
      "settlement_price_realized\n",
      "forecast_solar\n",
      "igcc_contribution_down_published\n",
      "vwap_max\n",
      "step 4\n",
      "step 6\n",
      "dict_keys(['left', 'right'])\n",
      "6       True\n",
      "7       True\n",
      "8       True\n",
      "9       True\n",
      "10      True\n",
      "       ...  \n",
      "899    False\n",
      "902    False\n",
      "966     True\n",
      "973     True\n",
      "974     True\n",
      "Name: fix_two_sided_ptu, Length: 203, dtype: bool\n",
      "2       True\n",
      "3       True\n",
      "4       True\n",
      "5       True\n",
      "86     False\n",
      "       ...  \n",
      "968     True\n",
      "969     True\n",
      "970     True\n",
      "971     True\n",
      "972     True\n",
      "Name: fix_two_sided_ptu, Length: 279, dtype: bool\n",
      "Layers to go = 1\n",
      "step 3\n",
      "naive_strategy_action\n",
      "min_ptu_price_known\n",
      "min_price_published\n",
      "forecast_wind\n",
      "time_since_last_two_sided\n",
      "two_sided_daily_count\n",
      "mid_price_published\n",
      "vwap_avg\n",
      "vwap_std\n",
      "vwap_qty_sum\n",
      "minute_in_ptu\n",
      "downward_dispatch_published\n",
      "settlement_price_bestguess\n",
      "import_capacity\n",
      "upward_dispatch_published\n",
      "settlement_price_realized\n",
      "forecast_solar\n",
      "igcc_contribution_down_published\n",
      "vwap_max\n",
      "step 4\n",
      "step 6\n",
      "dict_keys(['left', 'right'])\n",
      "Series([], Name: fix_two_sided_ptu, dtype: bool)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m df_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(splits[train_set][\u001b[38;5;241m3\u001b[39m][features \u001b[38;5;241m+\u001b[39m [target]])\n\u001b[0;32m----> 3\u001b[0m tree \u001b[38;5;241m=\u001b[39m \u001b[43mID3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(tree)\n",
      "Cell \u001b[0;32mIn[98], line 41\u001b[0m, in \u001b[0;36mID3\u001b[0;34m(data, target, max_depth)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m the_split\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     40\u001b[0m   df \u001b[38;5;241m=\u001b[39m the_split[key]\n\u001b[0;32m---> 41\u001b[0m   new_branch \u001b[38;5;241m=\u001b[39m \u001b[43mID3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m   branches\u001b[38;5;241m.\u001b[39mupdate({key: new_branch})\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# step 7\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[98], line 41\u001b[0m, in \u001b[0;36mID3\u001b[0;34m(data, target, max_depth)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m the_split\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     40\u001b[0m   df \u001b[38;5;241m=\u001b[39m the_split[key]\n\u001b[0;32m---> 41\u001b[0m   new_branch \u001b[38;5;241m=\u001b[39m \u001b[43mID3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m   branches\u001b[38;5;241m.\u001b[39mupdate({key: new_branch})\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# step 7\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[98], line 6\u001b[0m, in \u001b[0;36mID3\u001b[0;34m(data, target, max_depth)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data[target]\u001b[38;5;241m.\u001b[39mnunique() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m max_depth \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      5\u001b[0m   \u001b[38;5;28mprint\u001b[39m(data[target])\n\u001b[0;32m----> 6\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayers to go = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_depth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m max_depth \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/tweedejaars_project/lib/python3.12/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tweedejaars_project/lib/python3.12/site-packages/pandas/core/indexing.py:1752\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[0;32m-> 1752\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/miniconda3/envs/tweedejaars_project/lib/python3.12/site-packages/pandas/core/indexing.py:1685\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1683\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1685\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "df_train = pd.DataFrame(splits[train_set][3][features + [target]])\n",
    "\n",
    "tree = ID3(df_train[:1000], target, max_depth=2)\n",
    "print(tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, row):\n",
    "    node = tree.column_name\n",
    "    row_value = row[node]\n",
    "    branches = tree.branches\n",
    "\n",
    "    if row_value in branches:\n",
    "\n",
    "      # another Node is attached\n",
    "      if isinstance(branches[row_value], Node):\n",
    "        leaf = classify(branches[row_value], row)\n",
    "        return leaf\n",
    "\n",
    "      # this is a leaf node\n",
    "      elif (isinstance(branches[row_value], np.bool_) or\n",
    "          isinstance(branches[row_value], bool)):\n",
    "        return branches[row_value]\n",
    "\n",
    "      # there is only one key left in branch\n",
    "      else:\n",
    "        return branches[list(branches.keys())[0]].iloc[0]\n",
    "\n",
    "    else:\n",
    "        return tree.mode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweedejaars_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
