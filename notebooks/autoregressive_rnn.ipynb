{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model type: Autoregressive RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tweedejaars_project import *\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"import_capacity\",\n",
    "    \"mid_price_published\",\n",
    "    \"upward_dispatch_published\",\n",
    "    \"downward_dispatch_published\",\n",
    "    'min_ptu_price_known',\n",
    "    \"max_ptu_price_known\",\n",
    "    \"settlement_price_bestguess\",\n",
    "    'PTU',\n",
    "    'forecast_wind',\n",
    "    'forecast_solar',\n",
    "    'forecast_demand',\n",
    "    'time_since_last_two_sided',\n",
    "    'two_sided_daily_count',\n",
    "    'ptu_id',\n",
    "    'naive_strategy_action',\n",
    "    'minute_in_ptu',\n",
    "    \"hvq_delta\",\n",
    "    \"residual_load\",\n",
    "    \"dispatch_diff\",\n",
    "    \"igcc_diff\",\n",
    "    \"is_balanced\",\n",
    "    \"weekday\",\n",
    "    \"workday\",\n",
    "    \"hour\",\n",
    "    \"month\",\n",
    "    \"day\",\n",
    "    \"minute\",\n",
    "\n",
    "]\n",
    "# already used\n",
    "target = 'fix_two_sided_ptu_alt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple forward filling of features when NaN values are in columns\n",
    "def interpolate_feature(df, features):\n",
    "    for feature in features:\n",
    "        df[feature] = df[feature].ffill()\n",
    "    return df\n",
    "\n",
    "\n",
    "df = interpolate_feature(df, \n",
    "                        ['forecast_wind', 'forecast_solar', \n",
    "                         'forecast_demand', \"upward_dispatch_published\", \n",
    "                         \"downward_dispatch_published\", \"vwap_avg\",\n",
    "                        \"forecast_wind_delta\", \"forecast_solar_delta\",\n",
    "                        \"forecast_demand_delta\", \"residual_load\",\n",
    "                        \"dispatch_diff\", \"igcc_diff\", 'hvq_delta' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace two features with more informative bool feature\n",
    "def difference_published(df, features):\n",
    "    values = [0., 1., 2., 3.]\n",
    "    conditions = [\n",
    "        (df[features[0]].notna() & df[features[1]].isna()),  # feature1 has value, feature2 is NaN\n",
    "        (df[features[0]].isna() & df[features[1]].notna()),  # feature1 is NaN, feature2 has value\n",
    "        (df[features[0]].isna() & df[features[1]].isna()),   # both feature1 and feature2 are NaN\n",
    "        (df[features[0]].notna() & df[features[1]].notna())  # both feature1 and feature2 have values\n",
    "    ]\n",
    "    df['publish_info'] = np.select(conditions, values)\n",
    "    return df\n",
    "\n",
    "df = difference_published(df, ['min_price_published', 'max_price_published'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with 0 \n",
    "def fill_vals_0(df, features):\n",
    "    for feature in features:\n",
    "        df[feature] = df[feature].fillna(0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = fill_vals_0(df, ['min_ptu_price_known', 'max_ptu_price_known', 'settlement_price_bestguess'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(features)  # Input size == amount of Features\n",
    "hidden_size = 2\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "seq_length = 15  # 15 voor ptu_window dus 15 rows \n",
    "batch_size = seq_length * 15 \n",
    "num_epochs = 1\n",
    "learning_rate = 0.001\n",
    "patience = int(num_epochs * 0.75)\n",
    "\n",
    "\n",
    "splits = get_splits(df, features, target)\n",
    "# Split the data in vars\n",
    "train_data = splits['train']\n",
    "valid_data = splits['valid']\n",
    "test_data = splits['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, seq_length, using_train, probability=0.25):\n",
    "        # Initialize the dataset with data, sequence length, training flag, and probability for subsampling\n",
    "        self.data_in = pd.DataFrame(data['in']).astype(np.float32)\n",
    "        self.data_out = pd.Series(data['out']).astype(np.float32)\n",
    "        self.seq_length = seq_length\n",
    "        self.using_train = using_train\n",
    "        self.probability = probability\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples\n",
    "        return len(self.data_in)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Subsampling part only for training\n",
    "\n",
    "        # if self.using_train:\n",
    "        #     if not self.data_out.iloc[max(0, idx - self.seq_length + 1):idx + 1].any():\n",
    "        #         if np.random.rand() >= self.probability:\n",
    "        #             return torch.empty(0), torch.empty(0), 0\n",
    "\n",
    "        # Extract a sequence of length seq_length or truncate if at the start\n",
    "        if idx + 1 >= self.seq_length:\n",
    "            sequence = self.data_in.iloc[idx - self.seq_length + 1:idx + 1].values\n",
    "        else:\n",
    "            sequence = self.data_in.iloc[:idx + 1].values\n",
    "\n",
    "        # Get the target value\n",
    "        target = self.data_out.iloc[idx]\n",
    "        return torch.tensor(sequence, dtype=torch.float32), torch.tensor(target, dtype=torch.float32)\n",
    "\n",
    "# Custom collate function to handle variable-length sequences and padding\n",
    "def collate_fn(batch):\n",
    "    # Filter out empty tensors\n",
    "    batch = [item for item in batch if item[0].numel() > 0]\n",
    "\n",
    "    # Return empty tensors if the batch is empty\n",
    "    if len(batch) == 0:\n",
    "        return torch.empty(0), torch.empty(0), []\n",
    "\n",
    "    # Separate sequences and targets\n",
    "    sequences, targets = zip(*batch)\n",
    "\n",
    "    # Calculate the original lengths of the sequences\n",
    "    lengths = [len(seq) for seq in sequences]\n",
    "\n",
    "    # Pad the sequences to the length of the longest sequence in the batch\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "\n",
    "    return padded_sequences, torch.stack(targets), lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_loader(data, seq_length, batch_size, train=False):\n",
    "    dataset = TimeSeriesDataset(data, seq_length, train)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "train_loader = prepare_data_loader(train_data, seq_length, batch_size, train=True)\n",
    "valid_loader = prepare_data_loader(valid_data, seq_length, batch_size)\n",
    "test_loader = prepare_data_loader(test_data, seq_length, batch_size)\n",
    "\n",
    "print(f'expected batches training: {len(train_loader)}')\n",
    "print(f'expected batches validation: {len(valid_loader)}')\n",
    "print(f'expected batches testing: {len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Define an LSTM layer with dropout\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.5)\n",
    "        \n",
    "        # Define a fully connected layer for output\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Initialize cell state with zeros\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Pack padded sequence\n",
    "        packed_inputs = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(packed_inputs, (h0, c0))\n",
    "        \n",
    "        # Unpack packed sequence\n",
    "        unpacked_output, _ = pad_packed_sequence(out, batch_first=True)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(unpacked_output[:, -1, :])  # out: tensor of shape (batch_size, output_size)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, valid_loader, optimizer, criterion, num_epochs, device, scheduler=None, patience=10):\n",
    "    # Initialize lists to store losses and variables for early stopping\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    best_valid_loss = float('inf')\n",
    "    best_model_state_dict = None\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    # Loop over epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        train_loss = 0.0\n",
    "\n",
    "        # Loop over batches\n",
    "        for i, (inputs, targets, lengths) in enumerate(train_loader):\n",
    "            if len(inputs) == 0:  # Skip if batch is empty\n",
    "                continue\n",
    "\n",
    "            print(f\"Training batch {i}, Sequence shape: {inputs.shape}, Lengths: {lengths}\")\n",
    "            inputs, targets = inputs.to(device), targets.to(device)  # Move data to device\n",
    "            optimizer.zero_grad()  # Zero the gradients\n",
    "            outputs = model(inputs, lengths)  # Forward pass\n",
    "            loss = criterion(outputs.squeeze(), targets)  # Compute loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update parameters\n",
    "            train_loss += loss.item()  # Accumulate training loss\n",
    "\n",
    "        # Calculate validation loss after every epoch\n",
    "        valid_loss = evaluate(model, valid_loader, criterion, device)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss / len(train_loader):.4f}, Valid Loss: {valid_loss:.4f}')\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        # Step the scheduler if provided\n",
    "        if scheduler:\n",
    "            scheduler.step(valid_loss)\n",
    "\n",
    "        # Check for improvement in validation loss\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_model_state_dict = model.state_dict()\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == patience:  # Early stopping\n",
    "                print(f'Early stopping after {epoch+1} epochs.')\n",
    "                break\n",
    "\n",
    "    # Reload the best model state\n",
    "    print(f'Loading best model!')\n",
    "    model.load_state_dict(best_model_state_dict)\n",
    "\n",
    "    return train_losses, valid_losses\n",
    "\n",
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        # Loop over batches\n",
    "        for i, (inputs, targets, lengths) in enumerate(data_loader):\n",
    "            if len(inputs) == 0:  # Skip if batch is empty\n",
    "                continue\n",
    "\n",
    "            print(f\"Validation batch {i}, Sequence shape: {inputs.shape}, Lengths: {lengths}\")\n",
    "            inputs, targets = inputs.to(device), targets.to(device)  # Move data to device\n",
    "            outputs = model(inputs, lengths)  # Forward pass\n",
    "            loss = criterion(outputs.squeeze(), targets)  # Compute loss\n",
    "            total_loss += loss.item()  # Accumulate validation loss\n",
    "            \n",
    "    return total_loss / len(data_loader)  # Return average validation loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select device for training (GPU if available, else CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the model and move it to the selected device\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "\n",
    "# Create tensor for the target data and calculate class weights for imbalanced classes\n",
    "tensor_target = torch.tensor(train_data['out']).float()\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=(len(tensor_target) / tensor_target.sum() * 0.68))\n",
    "\n",
    "# Initialize optimizer with AdamW and AMSGrad variant\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, amsgrad=True)\n",
    "\n",
    "# Initialize learning rate scheduler to reduce LR on plateau\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=patience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, valid_losses = train(model, train_loader, valid_loader, optimizer, criterion, num_epochs, device, scheduler, patience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over all Batches')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(valid_losses, label='Validation Loss')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation Loss Over all Batches')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "save_name = 'autoregressive_rnn'\n",
    "folder_name = 'rnn'\n",
    "\n",
    "# Uncomment to save the model\n",
    "# save_model(model, save_name, folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the testing loop\n",
    "def test(model, test_loader, criterion, device):\n",
    "    # List to store all outputs\n",
    "    all_outputs = []\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    test_loss = 0.0  # Initialize the test loss\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for i, (inputs, targets, lengths) in enumerate(test_loader):\n",
    "            if len(inputs) == 0:  # Skip if batch is empty\n",
    "                continue\n",
    "\n",
    "            print(f\"Test batch {i}, Sequence shape: {inputs.shape}, Lengths: {targets.shape}\")\n",
    "\n",
    "            # Move inputs and targets to the specified device\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs, lengths)\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs.squeeze(), targets)\n",
    "            test_loss += loss.item()  # Accumulate the test loss\n",
    "\n",
    "            # Append the outputs to the list\n",
    "            all_outputs.append(outputs)\n",
    "\n",
    "    # Print the average test loss\n",
    "    print(f'Test Loss: {test_loss / len(test_loader):.4f}')\n",
    "    \n",
    "    # Concatenate all outputs and return\n",
    "    return torch.cat(all_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place to test model\n",
    "\n",
    "# change these two variables correctly to test different sets\n",
    "chosen_data_loader = valid_loader\n",
    "unaltered_df = valid_data['df']\n",
    "\n",
    "outputs = test(model, chosen_data_loader, criterion, device)\n",
    "probabilities = torch.sigmoid(outputs)\n",
    "predictions = (probabilities > 0.5)\n",
    "\n",
    "# choose correct df for the metric\n",
    "recasted_pred = recast_pred(predictions.flatten())\n",
    "show_metrics_adjusted(unaltered_df, recasted_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweedejaars_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
