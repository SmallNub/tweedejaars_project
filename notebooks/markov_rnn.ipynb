{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tweedejaars_project import *\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'import_capacity',\n",
    "    'min_price_published',\n",
    "    'mid_price_published',\n",
    "    'max_price_published',\n",
    "    # 'min_ptu_price_known',\n",
    "    # 'max_ptu_price_known',\n",
    "    # 'settlement_price_bestguess',\n",
    "    'time_since_last_two_sided',\n",
    "    'two_sided_daily_count',\n",
    "    'PTU',\n",
    "    'naive_strategy_action',\n",
    "    'forecast_wind',\n",
    "    'forecast_solar',\n",
    "    'forecast_demand',\n",
    "    'ptu_id',\n",
    "    'fix_two_sided_ptu_realtime'\n",
    "]\n",
    "\n",
    "# already used\n",
    "target = 'target_two_sided_ptu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df()\n",
    "splits = get_splits(df, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "sequence_length = 50 # Dit is het PTU aantal dus ptu_id's niet row aantal\n",
    "batch_size = 32\n",
    "input_size = len(features)\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Split the data in vars\n",
    "train_data = splits['train']\n",
    "test_data = splits['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_sequences(seq_length=50, ptu_length=15):\n",
    "#     sequence_indices = []\n",
    "#     ptu_ids_total = train_data['in']['ptu_id']\n",
    "#     ptu_ids = ptu_ids_total.unique()\n",
    "\n",
    "#     for ptu_id in ptu_ids:\n",
    "#         last_idx_start_ptu = np.searchsorted(ptu_ids_total, ptu_id, side='left')\n",
    "\n",
    "#         first_idx = last_idx_start_ptu - (seq_length * ptu_length)\n",
    "        \n",
    "#         if first_idx < 0:\n",
    "#             first_idx = 0\n",
    "\n",
    "#         # DIT IS EEN HACK WANT IK NEGEER NU DE EERSTE OM EEN GOEDE LENGTE TE HEBBEN VOOR ELKE INPUT\n",
    "#         # TODO: KAN WORDEN OPGELOST MET PADDING?\n",
    "#         for row_idx in range(ptu_length):\n",
    "#             last_idx = last_idx_start_ptu + row_idx\n",
    "#             sequence_indices.append((first_idx, last_idx))\n",
    "\n",
    "#     # niet meer nodig die id\n",
    "#     return sequence_indices\n",
    "\n",
    "# sequence_indices = create_sequences()\n",
    "# sequence_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST CODE \n",
    "# def create_sequences(data_in, seq_length, ptu_length):\n",
    "#     sequence_indices = []\n",
    "#     ptu_ids_total = data_in['ptu_id']\n",
    "#     ptu_ids = ptu_ids_total.unique()\n",
    "    \n",
    "#     for ptu_id in ptu_ids:\n",
    "#         last_idx_start_ptu = np.searchsorted(ptu_ids_total, ptu_id, side='left')\n",
    "\n",
    "#         for row_idx in range(ptu_length):\n",
    "#             last_idx = last_idx_start_ptu + row_idx\n",
    "#             first_idx = last_idx - (seq_length * ptu_length) + 1\n",
    "            \n",
    "#             if first_idx < 0:\n",
    "#                 first_idx = 0\n",
    "                \n",
    "#             sequence_indices.append((first_idx, last_idx))\n",
    "\n",
    "#     return sequence_indices\n",
    "\n",
    "# # Function to pad sequences\n",
    "# def pad_sequences(sequence, target, seq_length, ptu_length, num_features, nan_val1, nan_val2):\n",
    "#     max_rows = seq_length * ptu_length\n",
    "#     num_rows = sequence.shape[0]\n",
    "#     pad_rows = max(0, max_rows - num_rows)\n",
    "\n",
    "#     if pad_rows > 0:\n",
    "#         padding_sequence = np.full((pad_rows, num_features), fill_value=np.nan, dtype=np.float32)\n",
    "#         sequence = np.vstack((padding_sequence, sequence))\n",
    "#         padding_target = np.full((pad_rows,), fill_value=np.nan, dtype=np.float32)\n",
    "#         target = np.concatenate((padding_target, target))\n",
    "    \n",
    "#     return sequence, target\n",
    "\n",
    "# # Function to test sequence creation and padding\n",
    "# def test_sequences(train_data, seq_length, ptu_length, nan_val1, nan_val2):\n",
    "#     sequence_indices = create_sequences(train_data['in'], train_data['out'], seq_length, ptu_length)\n",
    "#     for idx, (start_idx, end_idx) in enumerate(sequence_indices):\n",
    "#         sequence = train_data['in'].iloc[start_idx:end_idx + 1].drop('ptu_id', axis=1).values\n",
    "#         target = train_data['out'].iloc[start_idx:end_idx + 1].values\n",
    "#         sequence, target = pad_sequences(sequence, target, seq_length, ptu_length, sequence.shape[1], nan_val1, nan_val2)\n",
    "#         print(f\"Sequence {idx}: {sequence.shape}, Target: {target.shape}, idx's [{start_idx, end_idx}]\")\n",
    "\n",
    "# # Hyperparameters\n",
    "\n",
    "# # test_sequences(train_data, seq_length, ptu_length, nan_val1, nan_val2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # def create_sequences(self):\n",
    "    #     sequence_indices = []\n",
    "    #     ptu_ids_total = self.data_in['ptu_id']\n",
    "    #     ptu_ids = ptu_ids_total.unique()\n",
    "\n",
    "    #     for ptu_id in ptu_ids:\n",
    "    #         last_idx_start_ptu = np.searchsorted(ptu_ids_total, ptu_id, side='left')\n",
    "\n",
    "    #         first_idx = last_idx_start_ptu - (self.seq_length * self.ptu_length)\n",
    "            \n",
    "    #         if first_idx < 0:\n",
    "    #             first_idx = 0\n",
    "\n",
    "    #         # DIT IS EEN HACK WANT IK NEGEER NU DE EERSTE OM EEN GOEDE LENGTE TE HEBBEN VOOR ELKE INPUT\n",
    "    #         # TODO: KAN WORDEN OPGELOST MET PADDING?\n",
    "    #         # if first_idx > 0:\n",
    "    #         for row_idx in range(self.ptu_length):\n",
    "    #             last_idx = last_idx_start_ptu + row_idx\n",
    "    #             sequence_indices.append((first_idx, last_idx))\n",
    "\n",
    "    #     # niet meer nodig die id\n",
    "    #     self.data_in = self.data_in.drop('ptu_id', axis=1)\n",
    "    #     return sequence_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, seq_length, ptu_length=15, nan_val1 = 100000, nan_val2 = -100000):\n",
    "        self.data_in = data['in'].astype(np.float32)\n",
    "        self.data_out = data['out'].astype(np.float32)\n",
    "        self.seq_length = seq_length\n",
    "        self.ptu_length = ptu_length\n",
    "        self.sequence_indices = self.create_sequences()\n",
    "\n",
    "        # DIT IS EEN HACK DUS WSS VERANDEREN\n",
    "        self.data_in = self.data_in.fillna({'min_price_published':nan_val1, 'max_price_published':nan_val2}).astype(np.float32)\n",
    "\n",
    "    def create_sequences(self):\n",
    "        sequence_indices = []\n",
    "        ptu_ids_total = self.data_in['ptu_id']\n",
    "        ptu_ids = ptu_ids_total.unique()\n",
    "        \n",
    "        for ptu_id in ptu_ids:\n",
    "            last_idx_start_ptu = np.searchsorted(ptu_ids_total, ptu_id, side='left')\n",
    "\n",
    "            for row_idx in range(self.ptu_length):\n",
    "                last_idx = last_idx_start_ptu + row_idx\n",
    "                first_idx = last_idx - (self.seq_length * self.ptu_length) + 1\n",
    "                \n",
    "                if first_idx < 0:\n",
    "                    first_idx = 0\n",
    "                    \n",
    "                sequence_indices.append((first_idx, last_idx))\n",
    "\n",
    "        return sequence_indices\n",
    "    \n",
    "    # sequence, target, seq_length, ptu_length, num_features, nan_val1, nan_val2\n",
    "    # def pad_sequences(self, sequence, target):\n",
    "    #     max_rows = self.seq_length * self.ptu_length\n",
    "    #     num_rows = sequence.shape[0]\n",
    "    #     num_features = sequence.shape[1]\n",
    "    #     pad_rows = max(0, max_rows - num_rows)\n",
    "\n",
    "    #     # FF opletten met die np.nan idk hoe goed dit gaat werken\n",
    "    #     if pad_rows > 0:\n",
    "    #         padding_sequence = np.full((pad_rows, num_features), fill_value=np.nan, dtype=np.float32)\n",
    "    #         sequence = np.vstack((padding_sequence, sequence))\n",
    "    #         padding_target = np.full((pad_rows,), fill_value=np.nan, dtype=np.float32)\n",
    "    #         target = np.concatenate((padding_target, target))\n",
    "\n",
    "        \n",
    "    #     return sequence, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence_indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        start_idx, end_idx = self.sequence_indices[idx]\n",
    "        sequence = self.data_in.iloc[start_idx:end_idx + 1].drop('ptu_id', axis=1).values\n",
    "        target = self.data_out.iloc[start_idx:end_idx + 1].values\n",
    "            \n",
    "        return torch.tensor(sequence, dtype=torch.float32), torch.tensor(target, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_loader(data, sequence_length, batch_size):\n",
    "    dataset = TimeSeriesDataset(data, sequence_length)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "        # Calculate the actual lengths of each sequence in the batch\n",
    "        lengths = torch.count_nonzero(~torch.isnan(x), dim=1).cpu()\n",
    "        \n",
    "        # Sort sequences by length\n",
    "        sorted_lengths, sorted_indices = lengths.sort(descending=True)\n",
    "        x_sorted = x[sorted_indices]\n",
    "        \n",
    "        # Pack the padded batch of sequences\n",
    "        packed_input = nn.utils.rnn.pack_padded_sequence(x_sorted, sorted_lengths, batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        packed_output, _ = self.rnn(packed_input)\n",
    "        \n",
    "        # Unpack the output\n",
    "        output, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(output)\n",
    "        out = torch.sigmoid(out[:, -1, :])\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9658, 0.1616, 0.0534],\n",
      "        [0.6900, 0.0018, 0.8960],\n",
      "        [0.5663, 0.5930, 0.5741],\n",
      "        [0.6836, 0.2389, 0.4567],\n",
      "        [0.6753, 0.9381, 0.0526],\n",
      "        [0.3978, 0.5444, 0.9855],\n",
      "        [0.3204, 0.9567, 0.2313],\n",
      "        [0.7106, 0.2493, 0.7830],\n",
      "        [0.3562, 0.2846, 0.2962],\n",
      "        [0.8869, 0.8583, 0.4654],\n",
      "        [0.1842, 0.6890, 0.4974],\n",
      "        [0.7305, 0.3030, 0.4937],\n",
      "        [0.8837, 0.8813, 0.5206],\n",
      "        [0.7902, 0.0288, 0.3473],\n",
      "        [0.9116, 0.9858, 0.7223],\n",
      "        [0.7183, 0.4518, 0.8939],\n",
      "        [0.6305, 0.1593, 0.4431],\n",
      "        [0.8508, 0.2299, 0.3121],\n",
      "        [0.5648, 0.2167, 0.3083],\n",
      "        [0.3356, 0.4826, 0.2622],\n",
      "        [0.5975, 0.3899, 0.3307],\n",
      "        [0.3482, 0.7138, 0.1033],\n",
      "        [0.0601, 0.1090, 0.9275],\n",
      "        [0.7493, 0.8437, 0.2948],\n",
      "        [0.5256, 0.3413, 0.8827],\n",
      "        [0.8071, 0.3404, 0.3854],\n",
      "        [0.9666, 0.1025, 0.0826],\n",
      "        [0.0135, 0.3791, 0.5936],\n",
      "        [0.6137, 0.0087, 0.6421],\n",
      "        [0.8512, 0.9123, 0.8577],\n",
      "        [0.3929, 0.9602, 0.0286],\n",
      "        [0.2496, 0.2807, 0.5085],\n",
      "        [0.1205, 0.2687, 0.6999],\n",
      "        [0.4793, 0.2797, 0.3457],\n",
      "        [0.0331, 0.4532, 0.0355],\n",
      "        [0.1341, 0.4725, 0.6783],\n",
      "        [0.4927, 0.5215, 0.5480],\n",
      "        [0.2440, 0.9882, 0.4635],\n",
      "        [0.7059, 0.4835, 0.7591],\n",
      "        [0.8732, 0.5201, 0.7319],\n",
      "        [0.5880, 0.1777, 0.7599],\n",
      "        [0.8853, 0.2025, 0.8177]])\n",
      "torch.Size([50, 3])\n",
      "torch.Size([42, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "source = torch.rand((42,3))\n",
    "print(source)\n",
    "# now we expand to size (7, 11) by appending a row of 0s at pos 0 and pos 6, \n",
    "# and a column of 0s at pos 10\n",
    "\n",
    "max_length = 50\n",
    "result = F.pad(input=source, pad=(0, 0, max(0, max_length - source.shape[0]), 0), mode='constant', value=np.nan)\n",
    "print(result.shape)\n",
    "filtered_tensor = result[~torch.all(result.isnan(),dim=1)]\n",
    "print(filtered_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 50, 5]) hallo\n",
      "Padded sequences shape: torch.Size([3, 50, 5])\n",
      "RNN output shape: torch.Size([3, 50, 20])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "\n",
    "# Generate sequences of varying lengths\n",
    "sequences = [torch.rand((42, 5)), torch.rand((30, 5)), torch.rand((35, 5))]\n",
    "desired_length = 50\n",
    "\n",
    "# Manually pad sequences to the desired length\n",
    "def pad_to_length(sequences, length, padding_value=np.nan):\n",
    "    padded_sequences = []\n",
    "    for seq in sequences:\n",
    "        if seq.shape[0] < length:\n",
    "            pad_length = length - seq.shape[0]\n",
    "            padded_seq = F.pad(seq, (0, 0, pad_length, 0), mode='constant', value=padding_value)\n",
    "        else:\n",
    "            padded_seq = seq[:length]\n",
    "        padded_sequences.append(padded_seq)\n",
    "    x = pad_sequence(padded_sequences, batch_first=True, padding_value=padding_value)\n",
    "    print(x.squeeze(0).shape, 'hallo')\n",
    "    return x\n",
    "\n",
    "# Pad sequences to the desired length\n",
    "padded_sequences_tensor = pad_to_length(sequences, desired_length)\n",
    "print(\"Padded sequences shape:\", padded_sequences_tensor.shape)\n",
    "\n",
    "# Define a simple RNN\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # Pack the padded sequence\n",
    "        packed_input = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.rnn(packed_input)\n",
    "        # Unpack the sequence\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True, total_length=desired_length)\n",
    "        return output\n",
    "\n",
    "# Get lengths of original sequences (before padding)\n",
    "sequence_lengths = [min(seq.shape[0], desired_length) for seq in sequences]\n",
    "\n",
    "# Instantiate the RNN with appropriate dimensions\n",
    "input_size = padded_sequences_tensor.shape[2]  # Number of features (5 in this case)\n",
    "hidden_size = 20  # Number of features in the hidden state\n",
    "num_layers = 1  # Number of recurrent layers\n",
    "rnn = SimpleRNN(input_size, hidden_size, num_layers)\n",
    "\n",
    "# Pass the padded sequences and their lengths to the RNN\n",
    "output = rnn(padded_sequences_tensor, sequence_lengths)\n",
    "print(\"RNN output shape:\", output.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = prepare_data_loader(train_data, sequence_length, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index_select(): Index is supposed to be a vector",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[313], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, masks, targets \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m      3\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 4\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39msqueeze(), targets)\n\u001b[1;32m      6\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tweedejaars_project/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tweedejaars_project/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[310], line 19\u001b[0m, in \u001b[0;36mRNNModel.forward\u001b[0;34m(self, x, lengths)\u001b[0m\n\u001b[1;32m     16\u001b[0m x_sorted \u001b[38;5;241m=\u001b[39m x[sorted_indices]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Pack the padded batch of sequences\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m packed_input \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpack_padded_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_sorted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msorted_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Forward propagate RNN\u001b[39;00m\n\u001b[1;32m     22\u001b[0m packed_output, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn(packed_input)\n",
      "File \u001b[0;32m~/miniconda3/envs/tweedejaars_project/lib/python3.12/site-packages/torch/nn/utils/rnn.py:261\u001b[0m, in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    259\u001b[0m     sorted_indices \u001b[38;5;241m=\u001b[39m sorted_indices\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    260\u001b[0m     batch_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msorted_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m data, batch_sizes \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    264\u001b[0m     _VF\u001b[38;5;241m.\u001b[39m_pack_padded_sequence(\u001b[38;5;28minput\u001b[39m, lengths, batch_first)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _packed_sequence_init(data, batch_sizes, sorted_indices, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index_select(): Index is supposed to be a vector"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for inputs, masks, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, masks)\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweedejaars_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
