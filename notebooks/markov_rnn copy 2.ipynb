{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tweedejaars_project import *\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"import_capacity\",\n",
    "    # \"min_price_published\",\n",
    "    \"mid_price_published\",\n",
    "    # \"max_price_published\",\n",
    "    # \"upward_dispatch_published\",\n",
    "    # \"downward_dispatch_published\",\n",
    "    # 'min_ptu_price_known',\n",
    "    # \"max_ptu_price_known\",\n",
    "    # \"settlement_price_bestguess\",\n",
    "    'PTU',\n",
    "    # 'forecast_wind',\n",
    "    # 'forecast_solar',\n",
    "    # 'forecast_demand',\n",
    "    'time_since_last_two_sided',\n",
    "    'two_sided_daily_count',\n",
    "    'ptu_id'\n",
    "]\n",
    "# already used\n",
    "target = 'target_two_sided_ptu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df()\n",
    "splits = get_splits(df, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            0\n",
      "1            0\n",
      "2            0\n",
      "3            0\n",
      "4            0\n",
      "          ... \n",
      "123835    8255\n",
      "123836    8255\n",
      "123837    8255\n",
      "123838    8255\n",
      "123839    8255\n",
      "Name: ptu_id, Length: 123840, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "ptu_window = 5 # Dit is het PTU aantal dus ptu_id's niet row aantal\n",
    "batch_size = 15000\n",
    "input_size = len(features)\n",
    "hidden_size = 16\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "num_epochs = 1\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Split the data in vars\n",
    "train_data = splits['train']\n",
    "# test_data = splits['test']\n",
    "\n",
    "rows = 20\n",
    "print(train_data['in']['ptu_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, ptu_window, ptu_length=15):\n",
    "        self.data_in = pd.DataFrame(data['in']).astype(np.float32)\n",
    "        self.data_out = pd.Series(data['out']).astype(np.float32)\n",
    "        self.ptu_window = ptu_window\n",
    "        self.ptu_length = ptu_length\n",
    "\n",
    "        self.ptu_history = self.ptu_window * self.ptu_length  # Entire window\n",
    "\n",
    "        self.sequence_indices, self.sequence_lengths = self.create_sequences()\n",
    "\n",
    "    def create_sequences(self):\n",
    "        sequence_indices, sequence_lengths = [], []\n",
    "\n",
    "        row_idx = 0  # Index of the current row\n",
    "        start_idx = 0  # Index of the furthest row in history\n",
    "\n",
    "        counter = self.ptu_length\n",
    "\n",
    "        for _ in range(len(self.data_in)):\n",
    "            sequence_indices.append((start_idx, row_idx))\n",
    "            sequence_lengths.append(row_idx - start_idx)  # Add length of sequence\n",
    "\n",
    "            if row_idx >= self.ptu_history:  # Start using the counter only after padding is passed\n",
    "                counter -= 1\n",
    "                if counter == 0:\n",
    "                    start_idx += self.ptu_length\n",
    "                    counter = self.ptu_length\n",
    "\n",
    "\n",
    "            row_idx += 1\n",
    "\n",
    "\n",
    "        return sequence_indices, sequence_lengths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx, row_idx = self.sequence_indices[idx]\n",
    "        length = self.sequence_lengths[idx]\n",
    "\n",
    "        # np array sequence and target \n",
    "        sequence = self.data_in.iloc[start_idx:row_idx + 1].values  \n",
    "        target = self.data_out.iloc[row_idx]\n",
    "\n",
    "        sequence = torch.tensor(sequence, dtype=torch.float32).flip(0)  # draai het om\n",
    "\n",
    "        # Dit wordt gebruikt voor padding alleen voor de eerdere getallen  waar de history nog incompleet is. \n",
    "        if length <= self.ptu_history and start_idx == 0:\n",
    "            # print(length, start_idx, row_idx)\n",
    "            sequence = F.pad(sequence, (0, 0, 0, (self.ptu_history - length) + self.ptu_length -1), mode='constant', value=np.nan)\n",
    "        \n",
    "        else:\n",
    "            # Padding for the dynamic rows in the current ptu\n",
    "            current_seq_len = self.ptu_length - ((row_idx - start_idx) % self.ptu_length)\n",
    "            sequence = F.pad(sequence, (0, 0, 0, current_seq_len - 1), mode='constant', value=np.nan)  # Extra padding\n",
    "        \n",
    "        # print(sequence.shape)\n",
    "\n",
    "        return sequence, torch.tensor(target, dtype=torch.float32), length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        packed_input = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.rnn(packed_input)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        # Use the last valid output for each sequence\n",
    "        idx = (lengths - 1).view(-1, 1).expand(output.size(0), output.size(2)).unsqueeze(1)\n",
    "        output = output.gather(1, idx).squeeze(1)\n",
    "        \n",
    "        output = self.fc(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_loader(data, ptu_window, batch_size):\n",
    "    dataset = TimeSeriesDataset(data, ptu_window)\n",
    "    # all_sequences, all_targets = dataset.get_all_sequences()\n",
    "    print('done')\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "train_loader = prepare_data_loader(train_data, ptu_window, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([15000, 90, 6])\n",
      "Labels batch shape: torch.Size([15000])\n",
      "lenghts: tensor([ 0,  1,  2,  ..., 87, 88, 89])\n"
     ]
    }
   ],
   "source": [
    "# TODO: eerste batch eerste item is puur nans?\n",
    "# TODO: Special NaN value for all inputs of NaN\n",
    "train_features, train_labels, lenghts = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "print(f'lenghts: {lenghts}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[7.0950e+02, 4.0390e+01, 1.1000e+01, 6.0000e+00, 1.0000e+00, 6.0000e+00],\n",
       "         [7.0950e+02, 4.0390e+01, 1.1000e+01, 5.9333e+00, 1.0000e+00, 6.0000e+00],\n",
       "         [7.0950e+02, 4.0390e+01, 1.1000e+01, 5.8667e+00, 1.0000e+00, 6.0000e+00],\n",
       "         [7.0950e+02, 4.0390e+01, 1.1000e+01, 5.8000e+00, 1.0000e+00, 6.0000e+00],\n",
       "         [7.0950e+02, 4.0390e+01, 1.1000e+01, 5.7333e+00, 1.0000e+00, 6.0000e+00],\n",
       "         [7.0950e+02, 4.0390e+01, 1.1000e+01, 5.6667e+00, 1.0000e+00, 6.0000e+00],\n",
       "         [7.0950e+02, 4.0390e+01, 1.1000e+01, 5.6000e+00, 1.0000e+00, 6.0000e+00],\n",
       "         [7.0950e+02, 4.0390e+01, 1.1000e+01, 5.5333e+00, 1.0000e+00, 6.0000e+00],\n",
       "         [7.0950e+02, 4.0390e+01, 1.1000e+01, 5.4667e+00, 1.0000e+00, 6.0000e+00],\n",
       "         [7.0950e+02, 4.0390e+01, 1.1000e+01, 5.4000e+00, 1.0000e+00, 6.0000e+00],\n",
       "         [7.0950e+02, 4.0390e+01, 1.1000e+01, 5.3333e+00, 1.0000e+00, 6.0000e+00],\n",
       "         [7.0950e+02, 4.0390e+01, 1.1000e+01, 5.2667e+00, 1.0000e+00, 6.0000e+00],\n",
       "         [7.0950e+02, 4.0390e+01, 1.1000e+01, 5.2000e+00, 1.0000e+00, 6.0000e+00],\n",
       "         [7.0950e+02, 3.9390e+01, 1.1000e+01, 5.1333e+00, 1.0000e+00, 6.0000e+00],\n",
       "         [7.0950e+02, 3.9390e+01, 1.1000e+01, 5.0667e+00, 1.0000e+00, 6.0000e+00],\n",
       "         [7.0950e+02, 3.9390e+01, 1.0000e+01, 5.0000e+00, 1.0000e+00, 5.0000e+00],\n",
       "         [7.0950e+02, 3.9390e+01, 1.0000e+01, 4.9333e+00, 1.0000e+00, 5.0000e+00],\n",
       "         [7.0950e+02, 3.9390e+01, 1.0000e+01, 4.8667e+00, 1.0000e+00, 5.0000e+00],\n",
       "         [7.0950e+02, 3.9390e+01, 1.0000e+01, 4.8000e+00, 1.0000e+00, 5.0000e+00],\n",
       "         [7.0950e+02, 3.9390e+01, 1.0000e+01, 4.7333e+00, 1.0000e+00, 5.0000e+00],\n",
       "         [7.0950e+02, 3.9390e+01, 1.0000e+01, 4.6667e+00, 1.0000e+00, 5.0000e+00],\n",
       "         [7.0950e+02, 3.9390e+01, 1.0000e+01, 4.6000e+00, 1.0000e+00, 5.0000e+00],\n",
       "         [7.0950e+02, 3.9390e+01, 1.0000e+01, 4.5333e+00, 1.0000e+00, 5.0000e+00],\n",
       "         [7.0950e+02, 3.9390e+01, 1.0000e+01, 4.4667e+00, 1.0000e+00, 5.0000e+00],\n",
       "         [7.0950e+02, 3.9390e+01, 1.0000e+01, 4.4000e+00, 1.0000e+00, 5.0000e+00],\n",
       "         [7.0950e+02, 3.9390e+01, 1.0000e+01, 4.3333e+00, 1.0000e+00, 5.0000e+00],\n",
       "         [7.0950e+02, 3.9390e+01, 1.0000e+01, 4.2667e+00, 1.0000e+00, 5.0000e+00],\n",
       "         [7.0950e+02, 3.9390e+01, 1.0000e+01, 4.2000e+00, 1.0000e+00, 5.0000e+00],\n",
       "         [7.0950e+02, 3.4980e+01, 1.0000e+01, 4.1333e+00, 1.0000e+00, 5.0000e+00],\n",
       "         [7.0950e+02, 3.4980e+01, 1.0000e+01, 4.0667e+00, 1.0000e+00, 5.0000e+00],\n",
       "         [7.0950e+02, 3.4980e+01, 9.0000e+00, 4.0000e+00, 1.0000e+00, 4.0000e+00],\n",
       "         [7.0950e+02, 3.4980e+01, 9.0000e+00, 3.9333e+00, 1.0000e+00, 4.0000e+00],\n",
       "         [7.0950e+02, 3.4980e+01, 9.0000e+00, 3.8667e+00, 1.0000e+00, 4.0000e+00],\n",
       "         [7.0950e+02, 3.4980e+01, 9.0000e+00, 3.8000e+00, 1.0000e+00, 4.0000e+00],\n",
       "         [7.0950e+02, 3.4980e+01, 9.0000e+00, 3.7333e+00, 1.0000e+00, 4.0000e+00],\n",
       "         [7.0950e+02, 3.4980e+01, 9.0000e+00, 3.6667e+00, 1.0000e+00, 4.0000e+00],\n",
       "         [7.0950e+02, 3.4980e+01, 9.0000e+00, 3.6000e+00, 1.0000e+00, 4.0000e+00],\n",
       "         [7.0950e+02, 3.4980e+01, 9.0000e+00, 3.5333e+00, 1.0000e+00, 4.0000e+00],\n",
       "         [7.0950e+02, 3.4980e+01, 9.0000e+00, 3.4667e+00, 1.0000e+00, 4.0000e+00],\n",
       "         [7.0950e+02, 3.4980e+01, 9.0000e+00, 3.4000e+00, 1.0000e+00, 4.0000e+00],\n",
       "         [7.0950e+02, 3.4980e+01, 9.0000e+00, 3.3333e+00, 1.0000e+00, 4.0000e+00],\n",
       "         [7.0950e+02, 3.4980e+01, 9.0000e+00, 3.2667e+00, 1.0000e+00, 4.0000e+00],\n",
       "         [7.0950e+02, 3.4980e+01, 9.0000e+00, 3.2000e+00, 1.0000e+00, 4.0000e+00],\n",
       "         [7.0950e+02, 4.4880e+01, 9.0000e+00, 3.1333e+00, 1.0000e+00, 4.0000e+00],\n",
       "         [7.0950e+02, 4.4880e+01, 9.0000e+00, 3.0667e+00, 1.0000e+00, 4.0000e+00],\n",
       "         [6.5400e+01, 4.4880e+01, 8.0000e+00, 3.0000e+00, 1.0000e+00, 3.0000e+00],\n",
       "         [6.5400e+01, 4.4880e+01, 8.0000e+00, 2.9333e+00, 1.0000e+00, 3.0000e+00],\n",
       "         [6.5400e+01, 4.4880e+01, 8.0000e+00, 2.8667e+00, 1.0000e+00, 3.0000e+00],\n",
       "         [6.5400e+01, 4.4880e+01, 8.0000e+00, 2.8000e+00, 1.0000e+00, 3.0000e+00],\n",
       "         [6.5400e+01, 4.4880e+01, 8.0000e+00, 2.7333e+00, 1.0000e+00, 3.0000e+00],\n",
       "         [6.5400e+01, 4.4880e+01, 8.0000e+00, 2.6667e+00, 1.0000e+00, 3.0000e+00],\n",
       "         [6.5400e+01, 4.4880e+01, 8.0000e+00, 2.6000e+00, 1.0000e+00, 3.0000e+00],\n",
       "         [6.5400e+01, 4.4880e+01, 8.0000e+00, 2.5333e+00, 1.0000e+00, 3.0000e+00],\n",
       "         [6.5400e+01, 4.4880e+01, 8.0000e+00, 2.4667e+00, 1.0000e+00, 3.0000e+00],\n",
       "         [6.5400e+01, 4.4880e+01, 8.0000e+00, 2.4000e+00, 1.0000e+00, 3.0000e+00],\n",
       "         [6.5400e+01, 4.4880e+01, 8.0000e+00, 2.3333e+00, 1.0000e+00, 3.0000e+00],\n",
       "         [6.5400e+01, 4.4880e+01, 8.0000e+00, 2.2667e+00, 1.0000e+00, 3.0000e+00],\n",
       "         [6.5400e+01, 4.4880e+01, 8.0000e+00, 2.2000e+00, 1.0000e+00, 3.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 8.0000e+00, 2.1333e+00, 1.0000e+00, 3.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 8.0000e+00, 2.0667e+00, 1.0000e+00, 3.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 7.0000e+00, 2.0000e+00, 1.0000e+00, 2.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 7.0000e+00, 1.9333e+00, 1.0000e+00, 2.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 7.0000e+00, 1.8667e+00, 1.0000e+00, 2.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 7.0000e+00, 1.8000e+00, 1.0000e+00, 2.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 7.0000e+00, 1.7333e+00, 1.0000e+00, 2.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 7.0000e+00, 1.6667e+00, 1.0000e+00, 2.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 7.0000e+00, 1.6000e+00, 1.0000e+00, 2.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 7.0000e+00, 1.5333e+00, 1.0000e+00, 2.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 7.0000e+00, 1.4667e+00, 1.0000e+00, 2.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 7.0000e+00, 1.4000e+00, 1.0000e+00, 2.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 7.0000e+00, 1.3333e+00, 1.0000e+00, 2.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 7.0000e+00, 1.2667e+00, 1.0000e+00, 2.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 7.0000e+00, 1.2000e+00, 1.0000e+00, 2.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 7.0000e+00, 1.1333e+00, 1.0000e+00, 2.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 7.0000e+00, 1.0667e+00, 1.0000e+00, 2.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 6.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 6.0000e+00, 9.3333e-01, 1.0000e+00, 1.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 6.0000e+00, 8.6667e-01, 1.0000e+00, 1.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 6.0000e+00, 8.0000e-01, 1.0000e+00, 1.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 6.0000e+00, 7.3333e-01, 1.0000e+00, 1.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 6.0000e+00, 6.6667e-01, 1.0000e+00, 1.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 6.0000e+00, 6.0000e-01, 1.0000e+00, 1.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 6.0000e+00, 5.3333e-01, 1.0000e+00, 1.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 6.0000e+00, 4.6667e-01, 1.0000e+00, 1.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 6.0000e+00, 4.0000e-01, 1.0000e+00, 1.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 6.0000e+00, 3.3333e-01, 1.0000e+00, 1.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 6.0000e+00, 2.6667e-01, 1.0000e+00, 1.0000e+00],\n",
       "         [6.5400e+01, 3.4970e+01, 6.0000e+00, 2.0000e-01, 1.0000e+00, 1.0000e+00],\n",
       "         [6.5400e+01, 3.3590e+01, 6.0000e+00, 1.3333e-01, 1.0000e+00, 1.0000e+00],\n",
       "         [6.5400e+01, 3.3590e+01, 6.0000e+00, 6.6667e-02, 1.0000e+00, 1.0000e+00]]),\n",
       " 89)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 104\n",
    "feature_tensor = train_features[x]\n",
    "lenght = lenghts[x].item()\n",
    "feature_tensor, lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0\n",
      "Sequence shape: torch.Size([15000, 90, 6])\n",
      "Targets shape: torch.Size([15000])\n",
      "tensor([ 1,  2,  3,  ..., 88, 89, 90])\n",
      "Batch: 1\n",
      "Sequence shape: torch.Size([15000, 90, 6])\n",
      "Targets shape: torch.Size([15000])\n",
      "tensor([76, 77, 78,  ..., 88, 89, 90])\n",
      "Batch: 2\n",
      "Sequence shape: torch.Size([15000, 90, 6])\n",
      "Targets shape: torch.Size([15000])\n",
      "tensor([76, 77, 78,  ..., 88, 89, 90])\n",
      "Batch: 3\n",
      "Sequence shape: torch.Size([15000, 90, 6])\n",
      "Targets shape: torch.Size([15000])\n",
      "tensor([76, 77, 78,  ..., 88, 89, 90])\n",
      "Batch: 4\n",
      "Sequence shape: torch.Size([15000, 90, 6])\n",
      "Targets shape: torch.Size([15000])\n",
      "tensor([76, 77, 78,  ..., 88, 89, 90])\n",
      "Batch: 5\n",
      "Sequence shape: torch.Size([15000, 90, 6])\n",
      "Targets shape: torch.Size([15000])\n",
      "tensor([76, 77, 78,  ..., 88, 89, 90])\n",
      "Batch: 6\n",
      "Sequence shape: torch.Size([15000, 90, 6])\n",
      "Targets shape: torch.Size([15000])\n",
      "tensor([76, 77, 78,  ..., 88, 89, 90])\n",
      "Batch: 7\n",
      "Sequence shape: torch.Size([15000, 90, 6])\n",
      "Targets shape: torch.Size([15000])\n",
      "tensor([76, 77, 78,  ..., 88, 89, 90])\n",
      "Batch: 8\n",
      "Sequence shape: torch.Size([3840, 90, 6])\n",
      "Targets shape: torch.Size([3840])\n",
      "tensor([76, 77, 78,  ..., 88, 89, 90])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (sequences, targets, lengths) in enumerate(train_loader):\n",
    "    print(\"Batch:\", batch_idx)\n",
    "    print(\"Sequence shape:\", sequences.shape)  # Print the shape of the input sequences\n",
    "    print(\"Targets shape:\", targets.shape)  # Print the shape of the targets\n",
    "    lengths += 1\n",
    "\n",
    "    # Ensure lengths is a 1D CPU int64 tensor\n",
    "    lengths = lengths.to(torch.int64).cpu()\n",
    "    print(lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0, Sequence shape: torch.Size([15000, 90, 6]), Lengths: tensor([ 1,  2,  3,  ..., 88, 89, 90])\n",
      "Batch 1, Sequence shape: torch.Size([15000, 90, 6]), Lengths: tensor([76, 77, 78,  ..., 88, 89, 90])\n",
      "Batch 2, Sequence shape: torch.Size([15000, 90, 6]), Lengths: tensor([76, 77, 78,  ..., 88, 89, 90])\n",
      "Batch 3, Sequence shape: torch.Size([15000, 90, 6]), Lengths: tensor([76, 77, 78,  ..., 88, 89, 90])\n",
      "Batch 4, Sequence shape: torch.Size([15000, 90, 6]), Lengths: tensor([76, 77, 78,  ..., 88, 89, 90])\n",
      "Batch 5, Sequence shape: torch.Size([15000, 90, 6]), Lengths: tensor([76, 77, 78,  ..., 88, 89, 90])\n",
      "Batch 6, Sequence shape: torch.Size([15000, 90, 6]), Lengths: tensor([76, 77, 78,  ..., 88, 89, 90])\n",
      "Batch 7, Sequence shape: torch.Size([15000, 90, 6]), Lengths: tensor([76, 77, 78,  ..., 88, 89, 90])\n",
      "Batch 8, Sequence shape: torch.Size([3840, 90, 6]), Lengths: tensor([76, 77, 78,  ..., 88, 89, 90])\n"
     ]
    }
   ],
   "source": [
    "def train_rnn(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, (sequences, targets, lengths) in enumerate(train_loader):\n",
    "            # Prepare the data\n",
    "            sequences = sequences.float()\n",
    "            targets = targets.float()\n",
    "            lengths += 1\n",
    "\n",
    "            # Ensure lengths is a 1D CPU int64 tensor\n",
    "            lengths = lengths.to(torch.int64).cpu()\n",
    "\n",
    "            # Debugging print statements\n",
    "            print(f\"Batch {batch_idx}, Sequence shape: {sequences.shape}, Lengths: {lengths}\")\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(sequences, lengths)\n",
    "            \n",
    "            # Compute loss\n",
    "            targets = targets.unsqueeze(1)  # Ensure targets have the shape (batch_size, 1)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "model = RNNModel(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_rnn(model, train_loader, criterion, optimizer, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, 'markov_2', 'rnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.9492\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, data_loader):\n",
    "    model.eval()\n",
    "    all_outputs = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for sequences, targets, lengths in data_loader:\n",
    "            sequences = sequences.float()\n",
    "            targets = targets.float()\n",
    "            lengths += 1\n",
    "\n",
    "            # Ensure lengths is a 1D CPU int64 tensor\n",
    "            lengths = lengths.to(torch.int64).cpu()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(sequences, lengths)\n",
    "            all_outputs.append(outputs)\n",
    "            all_targets.append(targets)\n",
    "            \n",
    "    return torch.cat(all_outputs), torch.cat(all_targets)\n",
    "\n",
    "loaded_model = load_model('markov_2', 'rnn')\n",
    "\n",
    "# Test the model on the training set\n",
    "outputs, targets = test_model(loaded_model, train_loader)\n",
    "\n",
    "# Convert outputs to probabilities\n",
    "probabilities = torch.sigmoid(outputs)\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "predictions = (probabilities > 0.5).float()\n",
    "\n",
    "# Evaluate the predictions\n",
    "accuracy = (predictions == targets.unsqueeze(1)).float().mean()\n",
    "print(f'Accuracy on training set: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1215.)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RNNModel(input_size, hidden_size, num_layers, output_size)\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, (sequences, targets) in enumerate(train_loader):\n",
    "#     print(\"Batch:\", batch_idx)\n",
    "#     print(\"Sequence shape:\", sequences.shape)  # Print the shape of the input sequences\n",
    "#     print(\"Targets shape:\", targets.shape)  # Print the shape of the targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training loop (placeholder, implement training logic)\n",
    "# for epoch in range(1):\n",
    "#     for sequences, targets in train_loader:\n",
    "#         lengths = [min(len(seq), sequence_length) for seq in sequences]\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(sequences, lengths)\n",
    "#         loss = criterion(outputs, targets)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweedejaars_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
